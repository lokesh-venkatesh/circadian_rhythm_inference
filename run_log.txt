(base) PS C:\Users\lokes\Desktop\circadian_rhythms\david_kyle_vae_model> python .\config.py

--- Running data.py ---
offset:  23.27571895
scale:   9.89200131
--- Finished data.py ---

--- Running train.py ---
2025-05-19 15:28:41.028221: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:From C:\Users\lokes\anaconda3\Lib\site-packages\keras\src\backend\tensorflow\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

Model: "encoder"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ Connected to               ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)      │ (None, 1536)              │               0 │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ reshape (Reshape)             │ (None, 1536, 1)           │               0 │ input_layer[0][0]          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d (Conv1D)               │ (None, 512, 40)           │             240 │ reshape[0][0]              │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_1 (Conv1D)             │ (None, 256, 40)           │           4,840 │ conv1d[0][0]               │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_2 (Conv1D)             │ (None, 128, 40)           │           4,840 │ conv1d_1[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_3 (Conv1D)             │ (None, 64, 40)            │           4,840 │ conv1d_2[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_4 (Conv1D)             │ (None, 32, 40)            │           4,840 │ conv1d_3[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_5 (Conv1D)             │ (None, 16, 20)            │           2,420 │ conv1d_4[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ get_item (GetItem)            │ (None, 16, 10)            │               0 │ conv1d_5[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ get_item_1 (GetItem)          │ (None, 16, 10)            │               0 │ conv1d_5[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ sampling (Sampling)           │ (None, 16, 10)            │               0 │ get_item[0][0],            │
│                               │                           │                 │ get_item_1[0][0]           │
└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘
 Total params: 22,020 (86.02 KB)
 Trainable params: 22,020 (86.02 KB)
 Non-trainable params: 0 (0.00 B)
Model: "decoder"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)           │ (None, None, 10)            │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose (Conv1DTranspose)   │ (None, None, 40)            │           1,240 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose_1 (Conv1DTranspose) │ (None, None, 40)            │           4,840 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose_2 (Conv1DTranspose) │ (None, None, 40)            │           4,840 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose_3 (Conv1DTranspose) │ (None, None, 40)            │           4,840 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose_4 (Conv1DTranspose) │ (None, None, 40)            │           4,840 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose_5 (Conv1DTranspose) │ (None, None, 1)             │             201 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ reshape_1 (Reshape)                  │ (None, None)                │               0 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 20,801 (81.25 KB)
 Trainable params: 20,801 (81.25 KB)
 Non-trainable params: 0 (0.00 B)
Model: "seasonal_prior"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ Connected to               ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer_2 (InputLayer)    │ (None, None, 6)           │               0 │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense (Dense)                 │ (None, None, 20)          │             120 │ input_layer_2[0][0]        │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ get_item_2 (GetItem)          │ (None, None, 10)          │               0 │ dense[0][0]                │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ get_item_3 (GetItem)          │ (None, None, 10)          │               0 │ dense[0][0]                │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ sampling_1 (Sampling)         │ (None, None, 10)          │               0 │ get_item_2[0][0],          │
│                               │                           │                 │ get_item_3[0][0]           │
└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘
 Total params: 120 (480.00 B)
 Trainable params: 120 (480.00 B)
 Non-trainable params: 0 (0.00 B)
Epoch 1/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 4s 48ms/step - loss: 1.3608 - val_kl: 0.0167 - val_loss: 1.3400 - val_recon: 1.3234
Epoch 2/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 38ms/step - loss: 1.2189 - val_kl: 0.0298 - val_loss: 1.0282 - val_recon: 0.9984
Epoch 3/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 37ms/step - loss: 0.9724 - val_kl: 0.0276 - val_loss: 0.9692 - val_recon: 0.9417
Epoch 4/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 35ms/step - loss: 0.9208 - val_kl: 0.0270 - val_loss: 0.9374 - val_recon: 0.9104
Epoch 5/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 43ms/step - loss: 0.8930 - val_kl: 0.0261 - val_loss: 0.9103 - val_recon: 0.8842
Epoch 6/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 36ms/step - loss: 0.8699 - val_kl: 0.0255 - val_loss: 0.8875 - val_recon: 0.8620
Epoch 7/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 36ms/step - loss: 0.8481 - val_kl: 0.0216 - val_loss: 0.8618 - val_recon: 0.8402
Epoch 8/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 38ms/step - loss: 0.8280 - val_kl: 0.0213 - val_loss: 0.8438 - val_recon: 0.8225
Epoch 9/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 34ms/step - loss: 0.8097 - val_kl: 0.0208 - val_loss: 0.8284 - val_recon: 0.8076
Epoch 10/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 37ms/step - loss: 0.7926 - val_kl: 0.0208 - val_loss: 0.8099 - val_recon: 0.7892
Epoch 11/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 38ms/step - loss: 0.7762 - val_kl: 0.0208 - val_loss: 0.7973 - val_recon: 0.7764
Epoch 12/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 38ms/step - loss: 0.7601 - val_kl: 0.0207 - val_loss: 0.7808 - val_recon: 0.7601
Epoch 13/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 39ms/step - loss: 0.7451 - val_kl: 0.0213 - val_loss: 0.7635 - val_recon: 0.7422
Epoch 14/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 39ms/step - loss: 0.7302 - val_kl: 0.0201 - val_loss: 0.7432 - val_recon: 0.7231
Epoch 15/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 27ms/step - loss: 0.7154 - val_kl: 0.0207 - val_loss: 0.7309 - val_recon: 0.7102
Epoch 16/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.7004 - val_kl: 0.0220 - val_loss: 0.7161 - val_recon: 0.6940
Epoch 17/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.6862 - val_kl: 0.0213 - val_loss: 0.7018 - val_recon: 0.6805
Epoch 18/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 22ms/step - loss: 0.6714 - val_kl: 0.0222 - val_loss: 0.6859 - val_recon: 0.6638
Epoch 19/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.6572 - val_kl: 0.0224 - val_loss: 0.6687 - val_recon: 0.6462
Epoch 20/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.6432 - val_kl: 0.0222 - val_loss: 0.6569 - val_recon: 0.6346
Epoch 21/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.6295 - val_kl: 0.0234 - val_loss: 0.6420 - val_recon: 0.6186
Epoch 22/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.6159 - val_kl: 0.0236 - val_loss: 0.6266 - val_recon: 0.6030
Epoch 23/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.6018 - val_kl: 0.0237 - val_loss: 0.6142 - val_recon: 0.5906
Epoch 24/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 27ms/step - loss: 0.5878 - val_kl: 0.0234 - val_loss: 0.5977 - val_recon: 0.5743
Epoch 25/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 28ms/step - loss: 0.5750 - val_kl: 0.0251 - val_loss: 0.5831 - val_recon: 0.5580
Epoch 26/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 27ms/step - loss: 0.5601 - val_kl: 0.0251 - val_loss: 0.5702 - val_recon: 0.5451
Epoch 27/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 35ms/step - loss: 0.5466 - val_kl: 0.0252 - val_loss: 0.5567 - val_recon: 0.5315
Epoch 28/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 38ms/step - loss: 0.5333 - val_kl: 0.0262 - val_loss: 0.5439 - val_recon: 0.5177
Epoch 29/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 36ms/step - loss: 0.5206 - val_kl: 0.0258 - val_loss: 0.5306 - val_recon: 0.5048
Epoch 30/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 37ms/step - loss: 0.5065 - val_kl: 0.0263 - val_loss: 0.5160 - val_recon: 0.4897
Epoch 31/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 38ms/step - loss: 0.4931 - val_kl: 0.0270 - val_loss: 0.5022 - val_recon: 0.4752
Epoch 32/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 27ms/step - loss: 0.4809 - val_kl: 0.0276 - val_loss: 0.4901 - val_recon: 0.4625
Epoch 33/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.4679 - val_kl: 0.0276 - val_loss: 0.4747 - val_recon: 0.4472
Epoch 34/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 22ms/step - loss: 0.4574 - val_kl: 0.0275 - val_loss: 0.4627 - val_recon: 0.4352
Epoch 35/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 22ms/step - loss: 0.4411 - val_kl: 0.0282 - val_loss: 0.4469 - val_recon: 0.4187
Epoch 36/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.4285 - val_kl: 0.0292 - val_loss: 0.4336 - val_recon: 0.4044
Epoch 37/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.4152 - val_kl: 0.0292 - val_loss: 0.4198 - val_recon: 0.3906
Epoch 38/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 22ms/step - loss: 0.4030 - val_kl: 0.0300 - val_loss: 0.4066 - val_recon: 0.3766
Epoch 39/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 22ms/step - loss: 0.3899 - val_kl: 0.0311 - val_loss: 0.3942 - val_recon: 0.3631
Epoch 40/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 22ms/step - loss: 0.3770 - val_kl: 0.0305 - val_loss: 0.3806 - val_recon: 0.3501
Epoch 41/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 22ms/step - loss: 0.3661 - val_kl: 0.0311 - val_loss: 0.3680 - val_recon: 0.3369
Epoch 42/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: 0.3532 - val_kl: 0.0310 - val_loss: 0.3513 - val_recon: 0.3204
Epoch 43/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.3391 - val_kl: 0.0310 - val_loss: 0.3387 - val_recon: 0.3076
Epoch 44/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.3291 - val_kl: 0.0330 - val_loss: 0.3273 - val_recon: 0.2944
Epoch 45/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.3168 - val_kl: 0.0331 - val_loss: 0.3173 - val_recon: 0.2842
Epoch 46/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.3018 - val_kl: 0.0331 - val_loss: 0.2995 - val_recon: 0.2663
Epoch 47/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.2888 - val_kl: 0.0342 - val_loss: 0.2893 - val_recon: 0.2552
Epoch 48/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.2764 - val_kl: 0.0343 - val_loss: 0.2763 - val_recon: 0.2420
Epoch 49/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.2647 - val_kl: 0.0350 - val_loss: 0.2635 - val_recon: 0.2284
Epoch 50/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.2526 - val_kl: 0.0360 - val_loss: 0.2524 - val_recon: 0.2164
Epoch 51/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.2399 - val_kl: 0.0365 - val_loss: 0.2366 - val_recon: 0.2001
Epoch 52/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.2282 - val_kl: 0.0366 - val_loss: 0.2266 - val_recon: 0.1900
Epoch 53/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.2152 - val_kl: 0.0383 - val_loss: 0.2118 - val_recon: 0.1735
Epoch 54/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.2058 - val_kl: 0.0383 - val_loss: 0.2088 - val_recon: 0.1705
Epoch 55/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.1930 - val_kl: 0.0392 - val_loss: 0.1882 - val_recon: 0.1491
Epoch 56/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.1796 - val_kl: 0.0401 - val_loss: 0.1737 - val_recon: 0.1336
Epoch 57/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.1684 - val_kl: 0.0404 - val_loss: 0.1603 - val_recon: 0.1199
Epoch 58/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.1579 - val_kl: 0.0407 - val_loss: 0.1526 - val_recon: 0.1119
Epoch 59/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.1453 - val_kl: 0.0410 - val_loss: 0.1345 - val_recon: 0.0935
Epoch 60/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.1310 - val_kl: 0.0425 - val_loss: 0.1246 - val_recon: 0.0821
Epoch 61/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: 0.1186 - val_kl: 0.0433 - val_loss: 0.1116 - val_recon: 0.0682
Epoch 62/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.1068 - val_kl: 0.0436 - val_loss: 0.0962 - val_recon: 0.0525
Epoch 63/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.0974 - val_kl: 0.0437 - val_loss: 0.0940 - val_recon: 0.0503
Epoch 64/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.0853 - val_kl: 0.0445 - val_loss: 0.0773 - val_recon: 0.0328
Epoch 65/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: 0.0731 - val_kl: 0.0444 - val_loss: 0.0621 - val_recon: 0.0177
Epoch 66/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.0606 - val_kl: 0.0457 - val_loss: 0.0504 - val_recon: 0.0047
Epoch 67/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.0479 - val_kl: 0.0468 - val_loss: 0.0372 - val_recon: -0.0096
Epoch 68/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: 0.0373 - val_kl: 0.0476 - val_loss: 0.0303 - val_recon: -0.0173
Epoch 69/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.0251 - val_kl: 0.0478 - val_loss: 0.0126 - val_recon: -0.0352
Epoch 70/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: 0.0142 - val_kl: 0.0493 - val_loss: 0.0016 - val_recon: -0.0477
Epoch 71/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: 0.0039 - val_kl: 0.0477 - val_loss: -0.0094 - val_recon: -0.0571
Epoch 72/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.0093 - val_kl: 0.0495 - val_loss: -0.0224 - val_recon: -0.0720
Epoch 73/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: -0.0197 - val_kl: 0.0509 - val_loss: -0.0304 - val_recon: -0.0813
Epoch 74/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: -0.0310 - val_kl: 0.0507 - val_loss: -0.0447 - val_recon: -0.0954
Epoch 75/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.0424 - val_kl: 0.0509 - val_loss: -0.0540 - val_recon: -0.1049
Epoch 76/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.0529 - val_kl: 0.0514 - val_loss: -0.0647 - val_recon: -0.1161
Epoch 77/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.0638 - val_kl: 0.0526 - val_loss: -0.0762 - val_recon: -0.1288
Epoch 78/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 28ms/step - loss: -0.0736 - val_kl: 0.0541 - val_loss: -0.0907 - val_recon: -0.1448
Epoch 79/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.0867 - val_kl: 0.0540 - val_loss: -0.1023 - val_recon: -0.1564
Epoch 80/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.0952 - val_kl: 0.0540 - val_loss: -0.1120 - val_recon: -0.1660
Epoch 81/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.1082 - val_kl: 0.0562 - val_loss: -0.1228 - val_recon: -0.1790
Epoch 82/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.1193 - val_kl: 0.0562 - val_loss: -0.1339 - val_recon: -0.1901
Epoch 83/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.1301 - val_kl: 0.0567 - val_loss: -0.1470 - val_recon: -0.2037
Epoch 84/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.1396 - val_kl: 0.0581 - val_loss: -0.1569 - val_recon: -0.2149
Epoch 85/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.1492 - val_kl: 0.0568 - val_loss: -0.1653 - val_recon: -0.2221
Epoch 86/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.1596 - val_kl: 0.0579 - val_loss: -0.1757 - val_recon: -0.2336
Epoch 87/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.1708 - val_kl: 0.0598 - val_loss: -0.1909 - val_recon: -0.2508
Epoch 88/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: -0.1794 - val_kl: 0.0611 - val_loss: -0.1916 - val_recon: -0.2527
Epoch 89/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.1879 - val_kl: 0.0611 - val_loss: -0.2097 - val_recon: -0.2707
Epoch 90/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.2004 - val_kl: 0.0617 - val_loss: -0.2191 - val_recon: -0.2808
Epoch 91/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.2100 - val_kl: 0.0623 - val_loss: -0.2306 - val_recon: -0.2929
Epoch 92/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.2202 - val_kl: 0.0639 - val_loss: -0.2443 - val_recon: -0.3082
Epoch 93/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.2316 - val_kl: 0.0647 - val_loss: -0.2496 - val_recon: -0.3143
Epoch 94/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.2370 - val_kl: 0.0650 - val_loss: -0.2599 - val_recon: -0.3249
Epoch 95/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.2506 - val_kl: 0.0665 - val_loss: -0.2748 - val_recon: -0.3413
Epoch 96/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.2610 - val_kl: 0.0669 - val_loss: -0.2780 - val_recon: -0.3449
Epoch 97/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.2709 - val_kl: 0.0677 - val_loss: -0.2903 - val_recon: -0.3580
Epoch 98/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.2794 - val_kl: 0.0691 - val_loss: -0.3017 - val_recon: -0.3708
Epoch 99/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.2911 - val_kl: 0.0696 - val_loss: -0.3079 - val_recon: -0.3775
Epoch 100/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.2970 - val_kl: 0.0700 - val_loss: -0.3234 - val_recon: -0.3934
Epoch 101/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.3053 - val_kl: 0.0715 - val_loss: -0.3118 - val_recon: -0.3833
Epoch 102/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.3171 - val_kl: 0.0724 - val_loss: -0.3386 - val_recon: -0.4110
Epoch 103/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.3272 - val_kl: 0.0725 - val_loss: -0.3502 - val_recon: -0.4226
Epoch 104/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.3369 - val_kl: 0.0718 - val_loss: -0.3594 - val_recon: -0.4312
Epoch 105/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.3446 - val_kl: 0.0754 - val_loss: -0.3572 - val_recon: -0.4327
Epoch 106/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.3497 - val_kl: 0.0743 - val_loss: -0.3771 - val_recon: -0.4514
Epoch 107/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.3594 - val_kl: 0.0764 - val_loss: -0.3868 - val_recon: -0.4632
Epoch 108/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: -0.3710 - val_kl: 0.0770 - val_loss: -0.3943 - val_recon: -0.4713
Epoch 109/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.3821 - val_kl: 0.0779 - val_loss: -0.4024 - val_recon: -0.4803
Epoch 110/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.3881 - val_kl: 0.0787 - val_loss: -0.4109 - val_recon: -0.4896
Epoch 111/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.3981 - val_kl: 0.0807 - val_loss: -0.4165 - val_recon: -0.4972
Epoch 112/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.3974 - val_kl: 0.0821 - val_loss: -0.4263 - val_recon: -0.5085
Epoch 113/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.4108 - val_kl: 0.0826 - val_loss: -0.4386 - val_recon: -0.5213
Epoch 114/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.4166 - val_kl: 0.0838 - val_loss: -0.4493 - val_recon: -0.5331
Epoch 115/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.4273 - val_kl: 0.0857 - val_loss: -0.4565 - val_recon: -0.5422
Epoch 116/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: -0.4346 - val_kl: 0.0855 - val_loss: -0.4661 - val_recon: -0.5516
Epoch 117/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.4471 - val_kl: 0.0876 - val_loss: -0.4751 - val_recon: -0.5627
Epoch 118/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 27ms/step - loss: -0.4531 - val_kl: 0.0871 - val_loss: -0.4727 - val_recon: -0.5597
Epoch 119/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 27ms/step - loss: -0.4613 - val_kl: 0.0876 - val_loss: -0.4918 - val_recon: -0.5794
Epoch 120/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 28ms/step - loss: -0.4710 - val_kl: 0.0898 - val_loss: -0.4973 - val_recon: -0.5870
Epoch 121/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.4716 - val_kl: 0.0889 - val_loss: -0.5042 - val_recon: -0.5931
Epoch 122/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 23ms/step - loss: -0.4739 - val_kl: 0.0911 - val_loss: -0.5115 - val_recon: -0.6026
Epoch 123/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.4884 - val_kl: 0.0924 - val_loss: -0.5206 - val_recon: -0.6130
Epoch 124/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.4960 - val_kl: 0.0933 - val_loss: -0.5235 - val_recon: -0.6168
Epoch 125/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.5010 - val_kl: 0.0946 - val_loss: -0.5355 - val_recon: -0.6301
Epoch 126/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.5137 - val_kl: 0.0946 - val_loss: -0.5426 - val_recon: -0.6373
Epoch 127/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.5201 - val_kl: 0.0962 - val_loss: -0.5491 - val_recon: -0.6453
Epoch 128/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.5228 - val_kl: 0.0970 - val_loss: -0.5521 - val_recon: -0.6491
Epoch 129/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.5294 - val_kl: 0.0968 - val_loss: -0.5571 - val_recon: -0.6539
Epoch 130/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.5373 - val_kl: 0.0989 - val_loss: -0.5677 - val_recon: -0.6666
Epoch 131/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.5276 - val_kl: 0.0989 - val_loss: -0.5774 - val_recon: -0.6764
Epoch 132/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.5194 - val_kl: 0.0990 - val_loss: -0.5714 - val_recon: -0.6704
Epoch 133/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.5544 - val_kl: 0.1006 - val_loss: -0.5904 - val_recon: -0.6910
Epoch 134/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.5628 - val_kl: 0.1018 - val_loss: -0.5950 - val_recon: -0.6968
Epoch 135/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.5694 - val_kl: 0.1030 - val_loss: -0.6004 - val_recon: -0.7034
Epoch 136/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.5743 - val_kl: 0.1034 - val_loss: -0.6082 - val_recon: -0.7116
Epoch 137/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.5759 - val_kl: 0.1044 - val_loss: -0.6128 - val_recon: -0.7171
Epoch 138/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.5768 - val_kl: 0.1043 - val_loss: -0.6205 - val_recon: -0.7248
Epoch 139/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.5874 - val_kl: 0.1061 - val_loss: -0.6229 - val_recon: -0.7290
Epoch 140/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.5883 - val_kl: 0.1053 - val_loss: -0.6278 - val_recon: -0.7331
Epoch 141/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6008 - val_kl: 0.1075 - val_loss: -0.6362 - val_recon: -0.7437
Epoch 142/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6056 - val_kl: 0.1078 - val_loss: -0.6398 - val_recon: -0.7476
Epoch 143/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6088 - val_kl: 0.1093 - val_loss: -0.6387 - val_recon: -0.7480
Epoch 144/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.6100 - val_kl: 0.1098 - val_loss: -0.6469 - val_recon: -0.7568
Epoch 145/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.6160 - val_kl: 0.1107 - val_loss: -0.6524 - val_recon: -0.7631
Epoch 146/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.6221 - val_kl: 0.1105 - val_loss: -0.6495 - val_recon: -0.7600
Epoch 147/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6218 - val_kl: 0.1120 - val_loss: -0.6554 - val_recon: -0.7673
Epoch 148/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.6170 - val_kl: 0.1145 - val_loss: -0.6688 - val_recon: -0.7833
Epoch 149/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6215 - val_kl: 0.1148 - val_loss: -0.6650 - val_recon: -0.7798
Epoch 150/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6370 - val_kl: 0.1149 - val_loss: -0.6816 - val_recon: -0.7965
Epoch 151/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6444 - val_kl: 0.1163 - val_loss: -0.6767 - val_recon: -0.7930
Epoch 152/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.6469 - val_kl: 0.1161 - val_loss: -0.6877 - val_recon: -0.8038
Epoch 153/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.6486 - val_kl: 0.1176 - val_loss: -0.6940 - val_recon: -0.8116
Epoch 154/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6553 - val_kl: 0.1187 - val_loss: -0.6900 - val_recon: -0.8087
Epoch 155/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6557 - val_kl: 0.1192 - val_loss: -0.6834 - val_recon: -0.8026
Epoch 156/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6467 - val_kl: 0.1204 - val_loss: -0.6610 - val_recon: -0.7814
Epoch 157/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6583 - val_kl: 0.1222 - val_loss: -0.6902 - val_recon: -0.8124
Epoch 158/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.6659 - val_kl: 0.1214 - val_loss: -0.7057 - val_recon: -0.8271
Epoch 159/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6723 - val_kl: 0.1237 - val_loss: -0.7099 - val_recon: -0.8336
Epoch 160/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.6750 - val_kl: 0.1243 - val_loss: -0.7079 - val_recon: -0.8321
Epoch 161/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.6785 - val_kl: 0.1245 - val_loss: -0.7203 - val_recon: -0.8448
Epoch 162/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6829 - val_kl: 0.1280 - val_loss: -0.7205 - val_recon: -0.8485
Epoch 163/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.6763 - val_kl: 0.1268 - val_loss: -0.7103 - val_recon: -0.8370
Epoch 164/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6546 - val_kl: 0.1265 - val_loss: -0.7219 - val_recon: -0.8484
Epoch 165/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.6736 - val_kl: 0.1293 - val_loss: -0.7339 - val_recon: -0.8632
Epoch 166/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6762 - val_kl: 0.1293 - val_loss: -0.7334 - val_recon: -0.8627
Epoch 167/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.6798 - val_kl: 0.1298 - val_loss: -0.7321 - val_recon: -0.8619
Epoch 168/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6949 - val_kl: 0.1308 - val_loss: -0.7432 - val_recon: -0.8740
Epoch 169/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.6989 - val_kl: 0.1308 - val_loss: -0.7417 - val_recon: -0.8726
Epoch 170/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.7004 - val_kl: 0.1313 - val_loss: -0.7485 - val_recon: -0.8798
Epoch 171/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.7052 - val_kl: 0.1316 - val_loss: -0.7443 - val_recon: -0.8758
Epoch 172/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7038 - val_kl: 0.1316 - val_loss: -0.7373 - val_recon: -0.8689
Epoch 173/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.7067 - val_kl: 0.1322 - val_loss: -0.7474 - val_recon: -0.8796
Epoch 174/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7024 - val_kl: 0.1342 - val_loss: -0.7362 - val_recon: -0.8704
Epoch 175/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7106 - val_kl: 0.1349 - val_loss: -0.7550 - val_recon: -0.8898
Epoch 176/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.7131 - val_kl: 0.1361 - val_loss: -0.7502 - val_recon: -0.8863
Epoch 177/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7109 - val_kl: 0.1346 - val_loss: -0.7347 - val_recon: -0.8693
Epoch 178/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.6652 - val_kl: 0.1333 - val_loss: -0.7614 - val_recon: -0.8947
Epoch 179/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 27ms/step - loss: -0.6505 - val_kl: 0.1339 - val_loss: -0.7384 - val_recon: -0.8723
Epoch 180/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7056 - val_kl: 0.1368 - val_loss: -0.7598 - val_recon: -0.8966
Epoch 181/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.7188 - val_kl: 0.1380 - val_loss: -0.7718 - val_recon: -0.9099
Epoch 182/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.7215 - val_kl: 0.1377 - val_loss: -0.7638 - val_recon: -0.9014
Epoch 183/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.7210 - val_kl: 0.1380 - val_loss: -0.7677 - val_recon: -0.9056
Epoch 184/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.7203 - val_kl: 0.1397 - val_loss: -0.7717 - val_recon: -0.9114
Epoch 185/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.7256 - val_kl: 0.1410 - val_loss: -0.7806 - val_recon: -0.9216
Epoch 186/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.7293 - val_kl: 0.1421 - val_loss: -0.7803 - val_recon: -0.9224
Epoch 187/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7278 - val_kl: 0.1436 - val_loss: -0.7729 - val_recon: -0.9165
Epoch 188/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7309 - val_kl: 0.1415 - val_loss: -0.7836 - val_recon: -0.9252
Epoch 189/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - loss: -0.7354 - val_kl: 0.1449 - val_loss: -0.7840 - val_recon: -0.9290
Epoch 190/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7341 - val_kl: 0.1456 - val_loss: -0.7822 - val_recon: -0.9278
Epoch 191/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7372 - val_kl: 0.1463 - val_loss: -0.7929 - val_recon: -0.9392
Epoch 192/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.7289 - val_kl: 0.1472 - val_loss: -0.7862 - val_recon: -0.9333
Epoch 193/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.7209 - val_kl: 0.1492 - val_loss: -0.7921 - val_recon: -0.9413
Epoch 194/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 28ms/step - loss: -0.7390 - val_kl: 0.1490 - val_loss: -0.7869 - val_recon: -0.9358
Epoch 195/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 27ms/step - loss: -0.7406 - val_kl: 0.1501 - val_loss: -0.8020 - val_recon: -0.9521
Epoch 196/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7423 - val_kl: 0.1509 - val_loss: -0.7798 - val_recon: -0.9307
Epoch 197/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7420 - val_kl: 0.1503 - val_loss: -0.7984 - val_recon: -0.9487
Epoch 198/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - loss: -0.7436 - val_kl: 0.1504 - val_loss: -0.8080 - val_recon: -0.9584
Epoch 199/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - loss: -0.7501 - val_kl: 0.1519 - val_loss: -0.8079 - val_recon: -0.9598
Epoch 200/200
29/29 ━━━━━━━━━━━━━━━━━━━━ 1s 27ms/step - loss: -0.7482 - val_kl: 0.1529 - val_loss: -0.7970 - val_recon: -0.9499
noise emission sigma:  0.099616945
Reconstruction loss:  -0.8984426
KL loss:              0.15318136
Total loss:           -0.74526125
--- Finished train.py ---

--- Running generate.py ---
2025-05-19 15:31:25.290222: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:From C:\Users\lokes\anaconda3\Lib\site-packages\keras\src\backend\tensorflow\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

Model: "encoder"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ Connected to               ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)      │ (None, 1536)              │               0 │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ reshape (Reshape)             │ (None, 1536, 1)           │               0 │ input_layer[0][0]          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d (Conv1D)               │ (None, 512, 40)           │             240 │ reshape[0][0]              │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_1 (Conv1D)             │ (None, 256, 40)           │           4,840 │ conv1d[0][0]               │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_2 (Conv1D)             │ (None, 128, 40)           │           4,840 │ conv1d_1[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_3 (Conv1D)             │ (None, 64, 40)            │           4,840 │ conv1d_2[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_4 (Conv1D)             │ (None, 32, 40)            │           4,840 │ conv1d_3[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_5 (Conv1D)             │ (None, 16, 20)            │           2,420 │ conv1d_4[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ get_item (GetItem)            │ (None, 16, 10)            │               0 │ conv1d_5[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ get_item_1 (GetItem)          │ (None, 16, 10)            │               0 │ conv1d_5[0][0]             │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ sampling (Sampling)           │ (None, 16, 10)            │               0 │ get_item[0][0],            │
│                               │                           │                 │ get_item_1[0][0]           │
└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘
 Total params: 22,020 (86.02 KB)
 Trainable params: 22,020 (86.02 KB)
 Non-trainable params: 0 (0.00 B)
Model: "decoder"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)           │ (None, None, 10)            │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose (Conv1DTranspose)   │ (None, None, 40)            │           1,240 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose_1 (Conv1DTranspose) │ (None, None, 40)            │           4,840 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose_2 (Conv1DTranspose) │ (None, None, 40)            │           4,840 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose_3 (Conv1DTranspose) │ (None, None, 40)            │           4,840 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose_4 (Conv1DTranspose) │ (None, None, 40)            │           4,840 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv1d_transpose_5 (Conv1DTranspose) │ (None, None, 1)             │             201 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ reshape_1 (Reshape)                  │ (None, None)                │               0 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 20,801 (81.25 KB)
 Trainable params: 20,801 (81.25 KB)
 Non-trainable params: 0 (0.00 B)
Model: "seasonal_prior"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ Connected to               ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer_2 (InputLayer)    │ (None, None, 6)           │               0 │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense (Dense)                 │ (None, None, 20)          │             120 │ input_layer_2[0][0]        │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ get_item_2 (GetItem)          │ (None, None, 10)          │               0 │ dense[0][0]                │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ get_item_3 (GetItem)          │ (None, None, 10)          │               0 │ dense[0][0]                │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ sampling_1 (Sampling)         │ (None, None, 10)          │               0 │ get_item_2[0][0],          │
│                               │                           │                 │ get_item_3[0][0]           │
└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘
 Total params: 120 (480.00 B)
 Trainable params: 120 (480.00 B)
 Non-trainable params: 0 (0.00 B)
Succesfully generated time series of length: 447065
--- Finished generate.py ---

--- Running plots.py ---
1970-01-01 00:00:00    2.721405
1970-01-01 01:00:00    1.544830
1970-01-01 02:00:00    1.555817
1970-01-01 03:00:00   -0.388367
1970-01-01 04:00:00   -0.291138
Name: Observed, dtype: float64
time
1970-01-01 00:00:00    10.061974
1970-01-01 01:00:00     9.279690
1970-01-01 02:00:00     8.698121
1970-01-01 03:00:00     7.692914
1970-01-01 04:00:00     7.787054
Name: temperature, dtype: float64
--- Finished plots.py ---

--- Running latent.py ---
Length of the latent vectors dataset: 1161
Length of the time-series vectors dataset: 1161
--- Finished latent.py ---
(base) PS C:\Users\lokes\Desktop\circadian_rhythms\david_kyle_vae_model>